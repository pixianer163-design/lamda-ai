#!/usr/bin/env python3
"""
æ€§èƒ½è·Ÿè¸ªä¸å¼‚å¸¸æ£€æµ‹æ¨¡å—

è®°å½•å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰ï¼Œå»ºç«‹åŸºçº¿ï¼Œæ£€æµ‹å¼‚å¸¸ã€‚
"""

import os
import json
import time
import statistics
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Callable
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None

try:
    from logger import get_logger
    _logger = get_logger()
    LOGGER_AVAILABLE = True
except ImportError:
    LOGGER_AVAILABLE = False
    _logger = None


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    EXECUTION_TIME = "execution_time"      # æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    MEMORY_USAGE = "memory_usage"          # å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
    CPU_USAGE = "cpu_usage"                # CPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    REQUEST_COUNT = "request_count"        # è¯·æ±‚è®¡æ•°
    ERROR_COUNT = "error_count"            # é”™è¯¯è®¡æ•°
    CUSTOM = "custom"                      # è‡ªå®šä¹‰æŒ‡æ ‡


@dataclass
class MetricRecord:
    """æŒ‡æ ‡è®°å½•"""
    metric_type: str
    value: float
    timestamp: datetime
    tags: Dict[str, str]
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "metric_type": self.metric_type,
            "value": self.value,
            "timestamp": self.timestamp.isoformat(),
            "tags": self.tags,
            "metadata": self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MetricRecord':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            metric_type=data["metric_type"],
            value=data["value"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            tags=data.get("tags", {}),
            metadata=data.get("metadata", {})
        )


@dataclass
class PerformanceBaseline:
    """æ€§èƒ½åŸºçº¿"""
    metric_type: str
    tags: Dict[str, str]
    window_days: int
    count: int
    mean: float
    std_dev: float
    min_value: float
    max_value: float
    percentile_95: float
    updated_at: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "metric_type": self.metric_type,
            "tags": self.tags,
            "window_days": self.window_days,
            "count": self.count,
            "mean": self.mean,
            "std_dev": self.std_dev,
            "min_value": self.min_value,
            "max_value": self.max_value,
            "percentile_95": self.percentile_95,
            "updated_at": self.updated_at.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'PerformanceBaseline':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            metric_type=data["metric_type"],
            tags=data.get("tags", {}),
            window_days=data.get("window_days", 7),
            count=data["count"],
            mean=data["mean"],
            std_dev=data["std_dev"],
            min_value=data["min_value"],
            max_value=data["max_value"],
            percentile_95=data["percentile_95"],
            updated_at=datetime.fromisoformat(data["updated_at"])
        )
    
    def is_anomaly(self, value: float, sigma_threshold: float = 3.0) -> Tuple[bool, float]:
        """
        æ£€æµ‹å€¼æ˜¯å¦ä¸ºå¼‚å¸¸
        
        Args:
            value: å¾…æ£€æµ‹å€¼
            sigma_threshold: æ ‡å‡†å·®é˜ˆå€¼ï¼ˆé»˜è®¤3Ïƒï¼‰
            
        Returns:
            (æ˜¯å¦å¼‚å¸¸, åç¦»æ ‡å‡†å·®çš„å€æ•°)
        """
        if self.std_dev == 0:
            deviation = abs(value - self.mean)
            is_anomaly = deviation > 0.1  # å¦‚æœæ ‡å‡†å·®ä¸º0ï¼Œä»»ä½•åå·®éƒ½è§†ä¸ºå¼‚å¸¸
            sigma = deviation
        else:
            sigma = abs(value - self.mean) / self.std_dev
            is_anomaly = sigma > sigma_threshold
        
        return is_anomaly, sigma


class PerformanceTracker:
    """æ€§èƒ½è·Ÿè¸ªå™¨"""
    
    def __init__(self, data_dir: Optional[str] = None, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.data_dir = Path(data_dir) if data_dir else Path(__file__).parent.parent / "data" / "performance"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‡æ ‡å­˜å‚¨
        self.metrics_file = self.data_dir / "metrics.json"
        self.baselines_file = self.data_dir / "baselines.json"
        
        # å†…å­˜ä¸­çš„æŒ‡æ ‡ç¼“å­˜ï¼ˆæœ€è¿‘çš„æ•°æ®ï¼‰
        self.metrics_cache: List[MetricRecord] = []
        self.max_cache_size = self.config.get('max_cache_size', 1000)
        
        # åŸºçº¿ç¼“å­˜
        self.baselines_cache: Dict[str, PerformanceBaseline] = {}
        
        # é”ç”¨äºçº¿ç¨‹å®‰å…¨
        self.lock = threading.RLock()
        
        # åŠ è½½ç°æœ‰æ•°æ®
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½å­˜å‚¨çš„æ•°æ®"""
        try:
            if self.metrics_file.exists():
                with open(self.metrics_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.metrics_cache = [MetricRecord.from_dict(item) for item in data[-self.max_cache_size:]]
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.warning(f"åŠ è½½æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
        
        try:
            if self.baselines_file.exists():
                with open(self.baselines_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.baselines_cache = {
                        f"{baseline['metric_type']}_{json.dumps(baseline['tags'], sort_keys=True)}": 
                        PerformanceBaseline.from_dict(baseline)
                        for baseline in data
                    }
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.warning(f"åŠ è½½æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")
    
    def _save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                data = [metric.to_dict() for metric in self.metrics_cache]
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.error(f"ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _save_baselines(self):
        """ä¿å­˜åŸºçº¿åˆ°æ–‡ä»¶"""
        try:
            with open(self.baselines_file, 'w', encoding='utf-8') as f:
                data = [baseline.to_dict() for baseline in self.baselines_cache.values()]
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.error(f"ä¿å­˜æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")
    
    def record_metric(self, metric_type: str, value: float, 
                      tags: Optional[Dict[str, str]] = None,
                      metadata: Optional[Dict[str, Any]] = None) -> MetricRecord:
        """
        è®°å½•æ€§èƒ½æŒ‡æ ‡
        
        Args:
            metric_type: æŒ‡æ ‡ç±»å‹
            value: æŒ‡æ ‡å€¼
            tags: æ ‡ç­¾ï¼ˆç”¨äºåˆ†ç±»ï¼‰
            metadata: å…ƒæ•°æ®
            
        Returns:
            åˆ›å»ºçš„è®°å½•
        """
        with self.lock:
            record = MetricRecord(
                metric_type=metric_type,
                value=value,
                timestamp=datetime.now(),
                tags=tags or {},
                metadata=metadata or {}
            )
            
            self.metrics_cache.append(record)
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.metrics_cache) > self.max_cache_size:
                self.metrics_cache = self.metrics_cache[-self.max_cache_size:]
            
            # å®šæœŸä¿å­˜
            if len(self.metrics_cache) % 100 == 0:
                self._save_metrics()
            
            return record
    
    def record_execution_time(self, operation: str, duration_seconds: float,
                              component: Optional[str] = None,
                              metadata: Optional[Dict[str, Any]] = None) -> MetricRecord:
        """
        è®°å½•æ‰§è¡Œæ—¶é—´
        
        Args:
            operation: æ“ä½œåç§°
            duration_seconds: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
            component: ç»„ä»¶åç§°
            metadata: å…ƒæ•°æ®
        """
        tags = {"operation": operation}
        if component:
            tags["component"] = component
        
        return self.record_metric(
            metric_type=MetricType.EXECUTION_TIME.value,
            value=duration_seconds,
            tags=tags,
            metadata=metadata
        )
    
    def record_memory_usage(self, component: Optional[str] = None,
                            metadata: Optional[Dict[str, Any]] = None) -> Optional[MetricRecord]:
        """
        è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ
        
        Args:
            component: ç»„ä»¶åç§°
            metadata: å…ƒæ•°æ®
        """
        if not PSUTIL_AVAILABLE:
            return None
        
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / (1024 * 1024)
            
            tags = {}
            if component:
                tags["component"] = component
            
            return self.record_metric(
                metric_type=MetricType.MEMORY_USAGE.value,
                value=memory_mb,
                tags=tags,
                metadata=metadata
            )
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.warning(f"è®°å½•å†…å­˜ä½¿ç”¨å¤±è´¥: {e}")
            return None
    
    def record_cpu_usage(self, component: Optional[str] = None,
                         metadata: Optional[Dict[str, Any]] = None) -> Optional[MetricRecord]:
        """
        è®°å½•CPUä½¿ç”¨ç‡
        
        Args:
            component: ç»„ä»¶åç§°
            metadata: å…ƒæ•°æ®
        """
        if not PSUTIL_AVAILABLE:
            return None
        
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            tags = {}
            if component:
                tags["component"] = component
            
            return self.record_metric(
                metric_type=MetricType.CPU_USAGE.value,
                value=cpu_percent,
                tags=tags,
                metadata=metadata
            )
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.warning(f"è®°å½•CPUä½¿ç”¨ç‡å¤±è´¥: {e}")
            return None
    
    def get_metrics(self, metric_type: Optional[str] = None,
                    tags: Optional[Dict[str, str]] = None,
                    start_time: Optional[datetime] = None,
                    end_time: Optional[datetime] = None) -> List[MetricRecord]:
        """
        è·å–æŒ‡æ ‡è®°å½•
        
        Args:
            metric_type: æŒ‡æ ‡ç±»å‹è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            
        Returns:
            è¿‡æ»¤åçš„æŒ‡æ ‡è®°å½•
        """
        with self.lock:
            filtered = self.metrics_cache.copy()
            
            # æŒ‰æŒ‡æ ‡ç±»å‹è¿‡æ»¤
            if metric_type:
                filtered = [m for m in filtered if m.metric_type == metric_type]
            
            # æŒ‰æ ‡ç­¾è¿‡æ»¤
            if tags:
                filtered = [
                    m for m in filtered
                    if all(m.tags.get(key) == value for key, value in tags.items())
                ]
            
            # æŒ‰æ—¶é—´è¿‡æ»¤
            if start_time:
                filtered = [m for m in filtered if m.timestamp >= start_time]
            if end_time:
                filtered = [m for m in filtered if m.timestamp <= end_time]
            
            return filtered
    
    def compute_baseline(self, metric_type: str, tags: Optional[Dict[str, str]] = None,
                         window_days: int = 7) -> Optional[PerformanceBaseline]:
        """
        è®¡ç®—æ€§èƒ½åŸºçº¿
        
        Args:
            metric_type: æŒ‡æ ‡ç±»å‹
            tags: æ ‡ç­¾è¿‡æ»¤
            window_days: æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰
            
        Returns:
            æ€§èƒ½åŸºçº¿ï¼ˆå¦‚æœæ•°æ®è¶³å¤Ÿï¼‰
        """
        # è·å–æ—¶é—´çª—å£å†…çš„æ•°æ®
        end_time = datetime.now()
        start_time = end_time - timedelta(days=window_days)
        
        metrics = self.get_metrics(metric_type, tags, start_time, end_time)
        
        if len(metrics) < 5:  # æœ€å°‘éœ€è¦5ä¸ªæ•°æ®ç‚¹
            if LOGGER_AVAILABLE and _logger:
                _logger.debug(f"æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•è®¡ç®—åŸºçº¿: {len(metrics)} < 5")
            return None
        
        values = [m.value for m in metrics]
        
        try:
            mean = statistics.mean(values)
            std_dev = statistics.stdev(values) if len(values) > 1 else 0
            min_value = min(values)
            max_value = max(values)
            
            # è®¡ç®—95ç™¾åˆ†ä½æ•°
            sorted_values = sorted(values)
            idx = int(0.95 * len(sorted_values))
            percentile_95 = sorted_values[idx] if idx < len(sorted_values) else sorted_values[-1]
            
            baseline = PerformanceBaseline(
                metric_type=metric_type,
                tags=tags or {},
                window_days=window_days,
                count=len(metrics),
                mean=mean,
                std_dev=std_dev,
                min_value=min_value,
                max_value=max_value,
                percentile_95=percentile_95,
                updated_at=datetime.now()
            )
            
            # ç¼“å­˜åŸºçº¿
            cache_key = f"{metric_type}_{json.dumps(tags or {}, sort_keys=True)}"
            self.baselines_cache[cache_key] = baseline
            
            # ä¿å­˜åŸºçº¿
            self._save_baselines()
            
            return baseline
            
        except Exception as e:
            if LOGGER_AVAILABLE and _logger:
                _logger.error(f"è®¡ç®—åŸºçº¿å¤±è´¥: {e}", exc_info=True)
            return None
    
    def get_or_compute_baseline(self, metric_type: str, tags: Optional[Dict[str, str]] = None,
                                window_days: int = 7, force_recompute: bool = False) -> Optional[PerformanceBaseline]:
        """
        è·å–æˆ–è®¡ç®—æ€§èƒ½åŸºçº¿
        
        Args:
            metric_type: æŒ‡æ ‡ç±»å‹
            tags: æ ‡ç­¾è¿‡æ»¤
            window_days: æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰
            force_recompute: å¼ºåˆ¶é‡æ–°è®¡ç®—
            
        Returns:
            æ€§èƒ½åŸºçº¿
        """
        cache_key = f"{metric_type}_{json.dumps(tags or {}, sort_keys=True)}"
        
        with self.lock:
            # æ£€æŸ¥ç¼“å­˜
            if not force_recompute and cache_key in self.baselines_cache:
                baseline = self.baselines_cache[cache_key]
                # æ£€æŸ¥åŸºçº¿æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡çª—å£æ—¶é—´çš„ä¸€åŠï¼‰
                baseline_age = datetime.now() - baseline.updated_at
                if baseline_age < timedelta(days=window_days / 2):
                    return baseline
            
            # è®¡ç®—æ–°åŸºçº¿
            return self.compute_baseline(metric_type, tags, window_days)
    
    def detect_anomaly(self, metric_type: str, value: float, 
                       tags: Optional[Dict[str, str]] = None,
                       sigma_threshold: float = 3.0) -> Tuple[bool, Optional[PerformanceBaseline], float]:
        """
        æ£€æµ‹æ€§èƒ½å¼‚å¸¸
        
        Args:
            metric_type: æŒ‡æ ‡ç±»å‹
            value: å¾…æ£€æµ‹å€¼
            tags: æ ‡ç­¾è¿‡æ»¤
            sigma_threshold: æ ‡å‡†å·®é˜ˆå€¼
            
        Returns:
            (æ˜¯å¦å¼‚å¸¸, åŸºçº¿å¯¹è±¡, åç¦»æ ‡å‡†å·®çš„å€æ•°)
        """
        baseline = self.get_or_compute_baseline(metric_type, tags)
        
        if not baseline:
            return False, None, 0
        
        is_anomaly, sigma = baseline.is_anomaly(value, sigma_threshold)
        
        return is_anomaly, baseline, sigma
    
    def track_execution(self, operation: str, component: Optional[str] = None,
                        metadata: Optional[Dict[str, Any]] = None) -> Callable:
        """
        åˆ›å»ºæ‰§è¡Œæ—¶é—´è·Ÿè¸ªè£…é¥°å™¨/ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            operation: æ“ä½œåç§°
            component: ç»„ä»¶åç§°
            metadata: å…ƒæ•°æ®
            
        Returns:
            è£…é¥°å™¨å‡½æ•°
        """
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    self.record_execution_time(
                        operation=operation,
                        duration_seconds=duration,
                        component=component,
                        metadata={**(metadata or {}), "function": func.__name__}
                    )
                    
                    # æ£€æµ‹å¼‚å¸¸
                    baseline_key = f"{MetricType.EXECUTION_TIME.value}_{json.dumps({'operation': operation, 'component': component} if component else {'operation': operation}, sort_keys=True)}"
                    if baseline_key in self.baselines_cache:
                        baseline = self.baselines_cache[baseline_key]
                        is_anomaly, sigma = baseline.is_anomaly(duration)
                        if is_anomaly:
                            if LOGGER_AVAILABLE and _logger:
                                _logger.warning(
                                    f"æ£€æµ‹åˆ°æ‰§è¡Œæ—¶é—´å¼‚å¸¸: {operation}, "
                                    f"å€¼={duration:.3f}s, å‡å€¼={baseline.mean:.3f}s, "
                                    f"æ ‡å‡†å·®={baseline.std_dev:.3f}, Ïƒ={sigma:.2f}"
                                )
            
            return wrapper
        return decorator
    
    def generate_report(self, days: int = 7) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        
        Args:
            days: æŠ¥å‘Šå¤©æ•°
            
        Returns:
            æ€§èƒ½æŠ¥å‘Š
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        
        # è·å–æ‰€æœ‰æŒ‡æ ‡
        metrics = self.get_metrics(start_time=start_time, end_time=end_time)
        
        # æŒ‰æŒ‡æ ‡ç±»å‹åˆ†ç»„
        metrics_by_type = {}
        for metric in metrics:
            if metric.metric_type not in metrics_by_type:
                metrics_by_type[metric.metric_type] = []
            metrics_by_type[metric.metric_type].append(metric)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        report = {
            "period": {
                "start": start_time.isoformat(),
                "end": end_time.isoformat(),
                "days": days
            },
            "total_metrics": len(metrics),
            "metrics_by_type": {},
            "baselines": {},
            "anomalies": []
        }
        
        # æ¯ç§æŒ‡æ ‡ç±»å‹çš„ç»Ÿè®¡
        for metric_type, type_metrics in metrics_by_type.items():
            values = [m.value for m in type_metrics]
            
            try:
                mean = statistics.mean(values) if values else 0
                std_dev = statistics.stdev(values) if len(values) > 1 else 0
                min_val = min(values) if values else 0
                max_val = max(values) if values else 0
                
                report["metrics_by_type"][metric_type] = {
                    "count": len(values),
                    "mean": mean,
                    "std_dev": std_dev,
                    "min": min_val,
                    "max": max_val,
                    "latest": values[-1] if values else None
                }
            except Exception:
                pass
        
        # åŸºçº¿ä¿¡æ¯
        for baseline in self.baselines_cache.values():
            report["baselines"][baseline.metric_type] = baseline.to_dict()
        
        # æ£€æµ‹æœ€è¿‘çš„å¼‚å¸¸
        recent_metrics = self.get_metrics(start_time=end_time - timedelta(hours=24))
        for metric in recent_metrics[-50:]:  # æ£€æŸ¥æœ€è¿‘50ä¸ªæŒ‡æ ‡
            is_anomaly, baseline, sigma = self.detect_anomaly(
                metric.metric_type, metric.value, metric.tags
            )
            if is_anomaly:
                report["anomalies"].append({
                    "metric_type": metric.metric_type,
                    "value": metric.value,
                    "timestamp": metric.timestamp.isoformat(),
                    "tags": metric.tags,
                    "sigma": sigma,
                    "baseline_mean": baseline.mean if baseline else None,
                    "baseline_std_dev": baseline.std_dev if baseline else None
                })
        
        return report


# å…¨å±€æ€§èƒ½è·Ÿè¸ªå™¨å®ä¾‹
_performance_tracker = None

def get_performance_tracker(config: Optional[Dict[str, Any]] = None) -> PerformanceTracker:
    """è·å–å…¨å±€æ€§èƒ½è·Ÿè¸ªå™¨å®ä¾‹"""
    global _performance_tracker
    if _performance_tracker is None:
        _performance_tracker = PerformanceTracker(config=config)
    return _performance_tracker

def track_execution(operation: str, component: Optional[str] = None,
                    metadata: Optional[Dict[str, Any]] = None) -> Callable:
    """è·Ÿè¸ªæ‰§è¡Œæ—¶é—´ï¼ˆè£…é¥°å™¨å·¥å‚ï¼‰"""
    tracker = get_performance_tracker()
    return tracker.track_execution(operation, component, metadata)

def record_execution_time(operation: str, duration_seconds: float,
                          component: Optional[str] = None,
                          metadata: Optional[Dict[str, Any]] = None) -> MetricRecord:
    """è®°å½•æ‰§è¡Œæ—¶é—´ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    tracker = get_performance_tracker()
    return tracker.record_execution_time(operation, duration_seconds, component, metadata)


if __name__ == '__main__':
    # æµ‹è¯•æ€§èƒ½è·Ÿè¸ªå™¨
    print("ğŸ§ª æµ‹è¯•æ€§èƒ½è·Ÿè¸ªå™¨...")
    
    tracker = PerformanceTracker()
    
    # è®°å½•ä¸€äº›æµ‹è¯•æŒ‡æ ‡
    for i in range(10):
        tracker.record_execution_time("test_operation", i * 0.1, "test_component")
        tracker.record_memory_usage("test_component")
    
    # è®¡ç®—åŸºçº¿
    baseline = tracker.compute_baseline(
        metric_type=MetricType.EXECUTION_TIME.value,
        tags={"operation": "test_operation", "component": "test_component"}
    )
    
    if baseline:
        print(f"âœ… åŸºçº¿è®¡ç®—æˆåŠŸ: å‡å€¼={baseline.mean:.3f}, æ ‡å‡†å·®={baseline.std_dev:.3f}")
        
        # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
        test_value = baseline.mean + 4 * baseline.std_dev
        is_anomaly, sigma = baseline.is_anomaly(test_value)
        print(f"  å¼‚å¸¸æ£€æµ‹: å€¼={test_value:.3f}, Ïƒ={sigma:.2f}, å¼‚å¸¸={is_anomaly}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = tracker.generate_report(days=1)
    print(f"ğŸ“Š æ€§èƒ½æŠ¥å‘Š: æ€»æŒ‡æ ‡æ•°={report['total_metrics']}")
    
    print("âœ… æ€§èƒ½è·Ÿè¸ªå™¨æµ‹è¯•å®Œæˆ")